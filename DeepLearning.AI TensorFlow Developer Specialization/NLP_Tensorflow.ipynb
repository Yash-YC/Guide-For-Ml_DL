{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Word Index =  {'<OOV>': 1, 'my': 2, 'love': 3, 'dog': 4, 'i': 5, 'you': 6, 'cat': 7, 'do': 8, 'think': 9, 'is': 10, 'amazing': 11}\n",
      "\n",
      "Sequences =  [[5, 3, 2, 4], [5, 3, 2, 7], [6, 3, 2, 4], [8, 6, 9, 2, 4, 10, 11]]\n",
      "\n",
      "Padded Sequences:\n",
      "[[ 0  5  3  2  4]\n",
      " [ 0  5  3  2  7]\n",
      " [ 0  6  3  2  4]\n",
      " [ 9  2  4 10 11]]\n",
      "\n",
      "Test Sequence =  [[5, 1, 3, 2, 4], [2, 4, 1, 2, 1]]\n",
      "\n",
      "Padded Test Sequence: \n",
      "[[0 0 0 0 0 5 1 3 2 4]\n",
      " [0 0 0 0 0 2 4 1 2 1]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "sentences = [\n",
    "    'I love my dog',\n",
    "    'I love my cat',\n",
    "    'You love my dog!',\n",
    "    'Do you think my dog is amazing?'\n",
    "]\n",
    "\n",
    "tokenizer = Tokenizer(num_words = 100, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(sentences)\n",
    "\n",
    "padded = pad_sequences(sequences, maxlen=5)\n",
    "print(\"\\nWord Index = \" , word_index)\n",
    "print(\"\\nSequences = \" , sequences)\n",
    "print(\"\\nPadded Sequences:\")\n",
    "print(padded)\n",
    "\n",
    "\n",
    "# Try with words that the tokenizer wasn't fit to\n",
    "test_data = [\n",
    "    'i really love my dog',\n",
    "    'my dog loves my manatee'\n",
    "]\n",
    "\n",
    "test_seq = tokenizer.texts_to_sequences(test_data)\n",
    "print(\"\\nTest Sequence = \", test_seq)\n",
    "\n",
    "padded = pad_sequences(test_seq, maxlen=10)\n",
    "print(\"\\nPadded Test Sequence: \")\n",
    "print(padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29657\n",
      "[  308 15115   679  3337  2298    48   382  2576 15116     6  2577  8434\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0]\n",
      "(26709, 40)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"sarcasm.json\", 'r') as f:\n",
    "    datastore = json.load(f)\n",
    "\n",
    "\n",
    "sentences = [] \n",
    "labels = []\n",
    "urls = []\n",
    "for item in datastore:\n",
    "    sentences.append(item['headline'])\n",
    "    labels.append(item['is_sarcastic'])\n",
    "    urls.append(item['article_link'])\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "tokenizer = Tokenizer(oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print(len(word_index))\n",
    "# print(word_index)\n",
    "sequences = tokenizer.texts_to_sequences(sentences)\n",
    "padded = pad_sequences(sequences, padding='post')\n",
    "print(padded[0])\n",
    "print(padded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Word Embeddings**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word embeddings are a type of word representation that allows words with similar meaning to have a similar representation.\n",
    "\n",
    "They are a distributed representation for text that is perhaps one of the key breakthroughs for the impressive performance of deep learning methods on challenging natural language processing problems.\n",
    "\n",
    "**\"One of the benefits of using dense and low-dimensional vectors is computational: the majority of neural network toolkits do not play well with very high-dimensional, sparse vectors. â€¦ The main benefit of the dense representations is generalization power: if we believe some features may provide similar clues, it is worthwhile to provide a representation that is able to capture these similarities\"**\n",
    "\n",
    "Three techniques that can be used to learn a word embedding from text data.\n",
    "- Embedding Layer\n",
    "- Word2Vec\n",
    "1. Continuous Bag-of-Words model  (CBOW)\n",
    "2. Skip-gram model\n",
    "- GloVe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 2 - Lab 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "imdb, info = tfds.load(\"imdb_reviews\", with_info=True, as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_data, test_data = imdb['train'], imdb['test']\n",
    "\n",
    "training_sentences = []\n",
    "training_labels = []\n",
    "\n",
    "testing_sentences = []\n",
    "testing_labels = []\n",
    "\n",
    "# str(s.tonumpy()) is needed in Python3 instead of just s.numpy()\n",
    "for s,l in train_data:\n",
    "  training_sentences.append(s.numpy().decode('utf8'))\n",
    "  training_labels.append(l.numpy())\n",
    "  \n",
    "for s,l in test_data:\n",
    "  testing_sentences.append(s.numpy().decode('utf8'))\n",
    "  testing_labels.append(l.numpy())\n",
    "  \n",
    "training_labels_final = np.array(training_labels)\n",
    "testing_labels_final = np.array(testing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "embedding_dim = 16\n",
    "max_length = 120\n",
    "trunc_type='post'\n",
    "oov_tok = \"<OOV>\"\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(training_sentences)\n",
    "word_index = tokenizer.word_index\n",
    "sequences = tokenizer.texts_to_sequences(training_sentences)\n",
    "padded = pad_sequences(sequences,maxlen=max_length, truncating=trunc_type)\n",
    "\n",
    "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
    "testing_padded = pad_sequences(testing_sequences,maxlen=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? this is the kind of film for a snowy sunday afternoon when the rest of the world can go ahead with its own business as you <OOV> into a big arm chair and <OOV> for a couple of hours wonderful performances from cher and nicolas cage as always gently row the plot along there are no <OOV> to cross no dangerous waters just a warm and witty <OOV> through new york life at its best a family film in every sense and one that deserves the praise it received\n",
      "This is the kind of film for a snowy Sunday afternoon when the rest of the world can go ahead with its own business as you descend into a big arm-chair and mellow for a couple of hours. Wonderful performances from Cher and Nicolas Cage (as always) gently row the plot along. There are no rapids to cross, no dangerous waters, just a warm and witty paddle through New York life at its best. A family film in every sense and one that deserves the praise it received.\n"
     ]
    }
   ],
   "source": [
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "def decode_review(text):\n",
    "    return ' '.join([reverse_word_index.get(i, '?') for i in text])\n",
    "\n",
    "print(decode_review(padded[3]))\n",
    "print(training_sentences[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 120, 16)           160000    \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 6)                 11526     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 171,533\n",
      "Trainable params: 171,533\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(6, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 0.4962 - accuracy: 0.7370 - val_loss: 0.3434 - val_accuracy: 0.8504\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.2457 - accuracy: 0.9048 - val_loss: 0.3650 - val_accuracy: 0.8436\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.0988 - accuracy: 0.9746 - val_loss: 0.4463 - val_accuracy: 0.8294\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.0276 - accuracy: 0.9962 - val_loss: 0.5286 - val_accuracy: 0.8279\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.0082 - accuracy: 0.9992 - val_loss: 0.5795 - val_accuracy: 0.8285- accu\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.0024 - accuracy: 0.9999 - val_loss: 0.6291 - val_accuracy: 0.8309\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 9.2174e-04 - accuracy: 1.0000 - val_loss: 0.6730 - val_accuracy: 0.8316\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 4.9221e-04 - accuracy: 1.0000 - val_loss: 0.7176 - val_accuracy: 0.8308\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 2.8757e-04 - accuracy: 1.0000 - val_loss: 0.7524 - val_accuracy: 0.8314\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 1.7261e-04 - accuracy: 1.0000 - val_loss: 0.7863 - val_accuracy: 0.8319\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ec27fc8788>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "model.fit(padded, training_labels_final, epochs=num_epochs, validation_data=(testing_padded, testing_labels_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 16)\n"
     ]
    }
   ],
   "source": [
    "e = model.layers[0]\n",
    "weights = e.get_weights()[0]\n",
    "print(weights.shape) # shape: (vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "out_v = io.open('vecs.tsv', 'w', encoding='utf-8')\n",
    "out_m = io.open('meta.tsv', 'w', encoding='utf-8')\n",
    "for word_num in range(1, vocab_size):\n",
    "  word = reverse_word_index[word_num]\n",
    "  embeddings = weights[word_num]\n",
    "  out_m.write(word + \"\\n\")\n",
    "  out_v.write('\\t'.join([str(x) for x in embeddings]) + \"\\n\")\n",
    "out_v.close()\n",
    "out_m.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11, 64, 102, 12, 7, 478, 1200]]\n"
     ]
    }
   ],
   "source": [
    "sentence = \"I really think this is amazing. honest.\"\n",
    "sequence = tokenizer.texts_to_sequences([sentence])\n",
    "print(sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scarasm data (lab 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "vocab_size = 10000\n",
    "embedding_dim = 16\n",
    "max_length = 100\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<OOV>\"\n",
    "training_size = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sarcasm.json\", 'r') as f:\n",
    "    datastore = json.load(f)\n",
    "\n",
    "sentences = []\n",
    "labels = []\n",
    "\n",
    "for item in datastore:\n",
    "    sentences.append(item['headline'])\n",
    "    labels.append(item['is_sarcastic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_sentences = sentences[0:training_size]\n",
    "testing_sentences = sentences[training_size:]\n",
    "training_labels = labels[0:training_size]\n",
    "testing_labels = labels[training_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(training_sentences)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
    "training_padded = pad_sequences(training_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
    "testing_padded = pad_sequences(testing_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need this block to get it to work with TensorFlow 2.x\n",
    "import numpy as np\n",
    "training_padded = np.array(training_padded)\n",
    "training_labels = np.array(training_labels)\n",
    "testing_padded = np.array(testing_padded)\n",
    "testing_labels = np.array(testing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(24, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 100, 16)           160000    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 24)                408       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 25        \n",
      "=================================================================\n",
      "Total params: 160,433\n",
      "Trainable params: 160,433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "625/625 - 2s - loss: 0.6831 - accuracy: 0.5586 - val_loss: 0.6699 - val_accuracy: 0.5639\n",
      "Epoch 2/30\n",
      "625/625 - 1s - loss: 0.5083 - accuracy: 0.7796 - val_loss: 0.4057 - val_accuracy: 0.8302\n",
      "Epoch 3/30\n",
      "625/625 - 1s - loss: 0.3345 - accuracy: 0.8669 - val_loss: 0.3679 - val_accuracy: 0.8396\n",
      "Epoch 4/30\n",
      "625/625 - 1s - loss: 0.2781 - accuracy: 0.8906 - val_loss: 0.3440 - val_accuracy: 0.8539\n",
      "Epoch 5/30\n",
      "625/625 - 2s - loss: 0.2423 - accuracy: 0.9065 - val_loss: 0.3417 - val_accuracy: 0.8538\n",
      "Epoch 6/30\n",
      "625/625 - 2s - loss: 0.2149 - accuracy: 0.9171 - val_loss: 0.3427 - val_accuracy: 0.8541\n",
      "Epoch 7/30\n",
      "625/625 - 2s - loss: 0.1920 - accuracy: 0.9262 - val_loss: 0.3503 - val_accuracy: 0.8565\n",
      "Epoch 8/30\n",
      "625/625 - 2s - loss: 0.1736 - accuracy: 0.9341 - val_loss: 0.3582 - val_accuracy: 0.8536\n",
      "Epoch 9/30\n",
      "625/625 - 2s - loss: 0.1569 - accuracy: 0.9430 - val_loss: 0.3748 - val_accuracy: 0.8514\n",
      "Epoch 10/30\n",
      "625/625 - 1s - loss: 0.1419 - accuracy: 0.9491 - val_loss: 0.3841 - val_accuracy: 0.8538\n",
      "Epoch 11/30\n",
      "625/625 - 1s - loss: 0.1308 - accuracy: 0.9542 - val_loss: 0.4073 - val_accuracy: 0.8487\n",
      "Epoch 12/30\n",
      "625/625 - 2s - loss: 0.1199 - accuracy: 0.9589 - val_loss: 0.4181 - val_accuracy: 0.8505\n",
      "Epoch 13/30\n",
      "625/625 - 1s - loss: 0.1102 - accuracy: 0.9627 - val_loss: 0.4378 - val_accuracy: 0.8490\n",
      "Epoch 14/30\n",
      "625/625 - 2s - loss: 0.1011 - accuracy: 0.9667 - val_loss: 0.4703 - val_accuracy: 0.8417\n",
      "Epoch 15/30\n",
      "625/625 - 1s - loss: 0.0936 - accuracy: 0.9694 - val_loss: 0.4899 - val_accuracy: 0.8386\n",
      "Epoch 16/30\n",
      "625/625 - 1s - loss: 0.0859 - accuracy: 0.9729 - val_loss: 0.5038 - val_accuracy: 0.8402\n",
      "Epoch 17/30\n",
      "625/625 - 2s - loss: 0.0800 - accuracy: 0.9737 - val_loss: 0.5253 - val_accuracy: 0.8404\n",
      "Epoch 18/30\n",
      "625/625 - 1s - loss: 0.0728 - accuracy: 0.9768 - val_loss: 0.5528 - val_accuracy: 0.8381\n",
      "Epoch 19/30\n",
      "625/625 - 1s - loss: 0.0684 - accuracy: 0.9789 - val_loss: 0.5780 - val_accuracy: 0.8334\n",
      "Epoch 20/30\n",
      "625/625 - 1s - loss: 0.0623 - accuracy: 0.9815 - val_loss: 0.6094 - val_accuracy: 0.8334\n",
      "Epoch 21/30\n",
      "625/625 - 1s - loss: 0.0611 - accuracy: 0.9804 - val_loss: 0.6337 - val_accuracy: 0.8308\n",
      "Epoch 22/30\n",
      "625/625 - 1s - loss: 0.0556 - accuracy: 0.9838 - val_loss: 0.6566 - val_accuracy: 0.8334\n",
      "Epoch 23/30\n",
      "625/625 - 1s - loss: 0.0509 - accuracy: 0.9848 - val_loss: 0.6906 - val_accuracy: 0.8302\n",
      "Epoch 24/30\n",
      "625/625 - 1s - loss: 0.0463 - accuracy: 0.9869 - val_loss: 0.7125 - val_accuracy: 0.8308\n",
      "Epoch 25/30\n",
      "625/625 - 1s - loss: 0.0438 - accuracy: 0.9882 - val_loss: 0.7414 - val_accuracy: 0.8275\n",
      "Epoch 26/30\n",
      "625/625 - 1s - loss: 0.0403 - accuracy: 0.9887 - val_loss: 0.7925 - val_accuracy: 0.8246\n",
      "Epoch 27/30\n",
      "625/625 - 1s - loss: 0.0382 - accuracy: 0.9896 - val_loss: 0.7972 - val_accuracy: 0.8258\n",
      "Epoch 28/30\n",
      "625/625 - 1s - loss: 0.0350 - accuracy: 0.9907 - val_loss: 0.8318 - val_accuracy: 0.8180\n",
      "Epoch 29/30\n",
      "625/625 - 1s - loss: 0.0330 - accuracy: 0.9912 - val_loss: 0.8778 - val_accuracy: 0.8210\n",
      "Epoch 30/30\n",
      "625/625 - 1s - loss: 0.0310 - accuracy: 0.9917 - val_loss: 0.9189 - val_accuracy: 0.8202\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "history = model.fit(training_padded, training_labels, epochs=num_epochs, validation_data=(testing_padded, testing_labels), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_graphs(history, string):\n",
    "  plt.plot(history.history[string])\n",
    "  plt.plot(history.history['val_'+string])\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(string)\n",
    "  plt.legend([string, 'val_'+string])\n",
    "  plt.show()\n",
    "  \n",
    "plot_graphs(history, \"accuracy\")\n",
    "plot_graphs(history, \"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "former <OOV> store clerk sues over secret 'black <OOV> for minority shoppers ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?\n",
      "mom starting to fear son's web series closest thing she will have to grandchild\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "def decode_sentence(text):\n",
    "    return ' '.join([reverse_word_index.get(i, '?') for i in text])\n",
    "\n",
    "print(decode_sentence(training_padded[0]))\n",
    "print(training_sentences[2])\n",
    "print(labels[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 16)\n"
     ]
    }
   ],
   "source": [
    "e = model.layers[0]\n",
    "weights = e.get_weights()[0]\n",
    "print(weights.shape) # shape: (vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9906756 ]\n",
      " [0.00160077]]\n"
     ]
    }
   ],
   "source": [
    "sentence = [\"granny starting to fear spiders in the garden might be real\", \"game of thrones season finale showing this sunday night\"]\n",
    "sequences = tokenizer.texts_to_sequences(sentence)\n",
    "padded = pad_sequences(sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "print(model.predict(padded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lab 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:TFDS datasets with text encoding are deprecated and will be removed in a future version. Instead, you should use the plain text version and tokenize the text using `tensorflow_text` (See: https://www.tensorflow.org/tutorials/tensorflow_text/intro#tfdata_example)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to C:\\Users\\Yash\\tensorflow_datasets\\imdb_reviews\\subwords8k\\1.0.0...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dl Size...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 84125825/84125825 [00:00<00:00, 581726775.48 MiB/s]\n",
      "Dl Completed...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  6.64 url/s]\n",
      "WARNING:absl:Dataset is using deprecated text encoder API which will be removed soon. Please use the plain_text version of the dataset and migrate to `tensorflow_text`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset imdb_reviews downloaded and prepared to C:\\Users\\Yash\\tensorflow_datasets\\imdb_reviews\\subwords8k\\1.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "imdb, info = tfds.load(\"imdb_reviews/subwords8k\", with_info=True, as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = imdb['train'], imdb['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = info.features['text'].encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(tokenizer.subwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized string is [6307, 2327, 4043, 2120, 2, 48, 4249, 4429, 7, 2652, 8050]\n",
      "The original string: TensorFlow, from basics to mastery\n"
     ]
    }
   ],
   "source": [
    "sample_string = 'TensorFlow, from basics to mastery'\n",
    "\n",
    "tokenized_string = tokenizer.encode(sample_string)\n",
    "print ('Tokenized string is {}'.format(tokenized_string))\n",
    "\n",
    "original_string = tokenizer.decode(tokenized_string)\n",
    "print ('The original string: {}'.format(original_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6307 ----> Ten\n",
      "2327 ----> sor\n",
      "4043 ----> Fl\n",
      "2120 ----> ow\n",
      "2 ----> , \n",
      "48 ----> from \n",
      "4249 ----> basi\n",
      "4429 ----> cs \n",
      "7 ----> to \n",
      "2652 ----> master\n",
      "8050 ----> y\n"
     ]
    }
   ],
   "source": [
    "for ts in tokenized_string:\n",
    "  print ('{} ----> {}'.format(ts, tokenizer.decode([ts])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_dataset = train_data.shuffle(BUFFER_SIZE)\n",
    "train_dataset = train_dataset.padded_batch(BATCH_SIZE, tf.compat.v1.data.get_output_shapes(train_dataset))\n",
    "test_dataset = test_data.padded_batch(BATCH_SIZE, tf.compat.v1.data.get_output_shapes(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 64)          523840    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 6)                 390       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 524,237\n",
      "Trainable params: 524,237\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 64\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(tokenizer.vocab_size, embedding_dim),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(6, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "391/391 [==============================] - 23s 60ms/step - loss: 0.6754 - accuracy: 0.5976 - val_loss: 0.6357 - val_accuracy: 0.6360\n",
      "Epoch 2/10\n",
      "391/391 [==============================] - 24s 61ms/step - loss: 0.5568 - accuracy: 0.7904 - val_loss: 0.4970 - val_accuracy: 0.8488\n",
      "Epoch 3/10\n",
      "391/391 [==============================] - 21s 55ms/step - loss: 0.4311 - accuracy: 0.8688 - val_loss: 0.4211 - val_accuracy: 0.8431\n",
      "Epoch 4/10\n",
      "391/391 [==============================] - 20s 52ms/step - loss: 0.3522 - accuracy: 0.8998 - val_loss: 0.3669 - val_accuracy: 0.8731\n",
      "Epoch 5/10\n",
      "391/391 [==============================] - 21s 55ms/step - loss: 0.3018 - accuracy: 0.9122 - val_loss: 0.3422 - val_accuracy: 0.8778\n",
      "Epoch 6/10\n",
      "391/391 [==============================] - 22s 57ms/step - loss: 0.2660 - accuracy: 0.9201 - val_loss: 0.3259 - val_accuracy: 0.8797\n",
      "Epoch 7/10\n",
      "391/391 [==============================] - 23s 58ms/step - loss: 0.2374 - accuracy: 0.9281 - val_loss: 0.3321 - val_accuracy: 0.8716\n",
      "Epoch 8/10\n",
      "391/391 [==============================] - 25s 63ms/step - loss: 0.2151 - accuracy: 0.9350 - val_loss: 0.3167 - val_accuracy: 0.8798\n",
      "Epoch 9/10\n",
      "391/391 [==============================] - 28s 71ms/step - loss: 0.1969 - accuracy: 0.9399 - val_loss: 0.3223 - val_accuracy: 0.8785\n",
      "Epoch 10/10\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.1815 - accuracy: 0.9459 - val_loss: 0.3487 - val_accuracy: 0.8718\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_dataset, epochs=num_epochs, validation_data=test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_graphs(history, string):\n",
    "  plt.plot(history.history[string])\n",
    "  plt.plot(history.history['val_'+string])\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(string)\n",
    "  plt.legend([string, 'val_'+string])\n",
    "  plt.show()\n",
    "  \n",
    "plot_graphs(history, \"accuracy\")\n",
    "plot_graphs(history, \"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8185, 64)\n"
     ]
    }
   ],
   "source": [
    "e = model.layers[0]\n",
    "weights = e.get_weights()[0]\n",
    "print(weights.shape) # shape: (vocab_size, embedding_dim)\n",
    "\n",
    "import io\n",
    "\n",
    "out_v = io.open('vecs.tsv', 'w', encoding='utf-8')\n",
    "out_m = io.open('meta.tsv', 'w', encoding='utf-8')\n",
    "for word_num in range(1, tokenizer.vocab_size):\n",
    "  word = tokenizer.decode([word_num])\n",
    "  embeddings = weights[word_num]\n",
    "  out_m.write(word + \"\\n\")\n",
    "  out_v.write('\\t'.join([str(x) for x in embeddings]) + \"\\n\")\n",
    "out_v.close()\n",
    "out_m.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Sequence Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "week 3 - lab 1 & 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Single layer LSTM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:TFDS datasets with text encoding are deprecated and will be removed in a future version. Instead, you should use the plain text version and tokenize the text using `tensorflow_text` (See: https://www.tensorflow.org/tutorials/tensorflow_text/intro#tfdata_example)\n"
     ]
    }
   ],
   "source": [
    "# Get the data\n",
    "dataset, info = tfds.load('imdb_reviews/subwords8k', with_info=True, as_supervised=True)\n",
    "train_dataset, test_dataset = dataset['train'], dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = info.features['text'].encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE)\n",
    "train_dataset = train_dataset.padded_batch(BATCH_SIZE, tf.compat.v1.data.get_output_shapes(train_dataset))\n",
    "test_dataset = test_dataset.padded_batch(BATCH_SIZE, tf.compat.v1.data.get_output_shapes(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(tokenizer.vocab_size, 64),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 64)          523840    \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 128)               66048     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 598,209\n",
      "Trainable params: 598,209\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 10\n",
    "history = model.fit(train_dataset, epochs=NUM_EPOCHS, validation_data=test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_graphs(history, string):\n",
    "  plt.plot(history.history[string])\n",
    "  plt.plot(history.history['val_'+string])\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(string)\n",
    "  plt.legend([string, 'val_'+string])\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graphs(history, 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graphs(history, 'loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Multiple Layer LSTM**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = info.features['text'].encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE)\n",
    "train_dataset = train_dataset.padded_batch(BATCH_SIZE, tf.compat.v1.data.get_output_shapes(train_dataset))\n",
    "test_dataset = test_dataset.padded_batch(BATCH_SIZE, tf.compat.v1.data.get_output_shapes(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(tokenizer.vocab_size, 64),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 10\n",
    "history = model.fit(train_dataset, epochs=NUM_EPOCHS, validation_data=test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_graphs(history, string):\n",
    "  plt.plot(history.history[string])\n",
    "  plt.plot(history.history['val_'+string])\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(string)\n",
    "  plt.legend([string, 'val_'+string])\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graphs(history, 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graphs(history, 'loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lab 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = info.features['text'].encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE)\n",
    "train_dataset = train_dataset.padded_batch(BATCH_SIZE, tf.compat.v1.data.get_output_shapes(train_dataset))\n",
    "test_dataset = test_dataset.padded_batch(BATCH_SIZE, tf.compat.v1.data.get_output_shapes(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(tokenizer.vocab_size, 64),\n",
    "    tf.keras.layers.Conv1D(128, 5, activation='relu'),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 10\n",
    "history = model.fit(train_dataset, epochs=NUM_EPOCHS, validation_data=test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_graphs(history, string):\n",
    "  plt.plot(history.history[string])\n",
    "  plt.plot(history.history['val_'+string])\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(string)\n",
    "  plt.legend([string, 'val_'+string])\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graphs(history, 'accuracy')\n",
    "plot_graphs(history, 'loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lab 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "\n",
    "train_data, test_data = imdb['train'], imdb['test']\n",
    "\n",
    "training_sentences = []\n",
    "training_labels = []\n",
    "\n",
    "testing_sentences = []\n",
    "testing_labels = []\n",
    "\n",
    "# str(s.tonumpy()) is needed in Python3 instead of just s.numpy()\n",
    "for s,l in train_data:\n",
    "  training_sentences.append(str(s.numpy()))\n",
    "  training_labels.append(l.numpy())\n",
    "  \n",
    "for s,l in test_data:\n",
    "  testing_sentences.append(str(s.numpy()))\n",
    "  testing_labels.append(l.numpy())\n",
    "  \n",
    "training_labels_final = np.array(training_labels)\n",
    "testing_labels_final = np.array(testing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "embedding_dim = 16\n",
    "max_length = 120\n",
    "trunc_type='post'\n",
    "oov_tok = \"<OOV>\"\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(training_sentences)\n",
    "word_index = tokenizer.word_index\n",
    "sequences = tokenizer.texts_to_sequences(training_sentences)\n",
    "padded = pad_sequences(sequences,maxlen=max_length, truncating=trunc_type)\n",
    "\n",
    "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
    "testing_padded = pad_sequences(testing_sequences,maxlen=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "def decode_review(text):\n",
    "    return ' '.join([reverse_word_index.get(i, '?') for i in text])\n",
    "\n",
    "print(decode_review(padded[1]))\n",
    "print(training_sentences[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.GRU(32)),\n",
    "    tf.keras.layers.Dense(6, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "history = model.fit(padded, training_labels_final, epochs=num_epochs, validation_data=(testing_padded, testing_labels_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_graphs(history, string):\n",
    "  plt.plot(history.history[string])\n",
    "  plt.plot(history.history['val_'+string])\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(string)\n",
    "  plt.legend([string, 'val_'+string])\n",
    "  plt.show()\n",
    "\n",
    "plot_graphs(history, 'accuracy')\n",
    "plot_graphs(history, 'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Definition with LSTM\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
    "    tf.keras.layers.Dense(6, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Definition with Conv1D\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.Conv1D(128, 5, activation='relu'),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(6, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 5 & 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import json\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "vocab_size = 1000\n",
    "embedding_dim = 16\n",
    "max_length = 120\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<OOV>\"\n",
    "training_size = 20000\n",
    "\n",
    "\n",
    "with open(\"sarcasm.json\", 'r') as f:\n",
    "    datastore = json.load(f)\n",
    "\n",
    "\n",
    "sentences = []\n",
    "labels = []\n",
    "urls = []\n",
    "for item in datastore:\n",
    "    sentences.append(item['headline'])\n",
    "    labels.append(item['is_sarcastic'])\n",
    "\n",
    "training_sentences = sentences[0:training_size]\n",
    "testing_sentences = sentences[training_size:]\n",
    "training_labels = labels[0:training_size]\n",
    "testing_labels = labels[training_size:]\n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(training_sentences)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
    "training_padded = pad_sequences(training_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
    "testing_padded = pad_sequences(testing_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
    "    tf.keras.layers.Dense(24, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "num_epochs = 50\n",
    "training_padded = np.array(training_padded)\n",
    "training_labels = np.array(training_labels)\n",
    "testing_padded = np.array(testing_padded)\n",
    "testing_labels = np.array(testing_labels)\n",
    "history = model.fit(training_padded, training_labels, epochs=num_epochs, validation_data=(testing_padded, testing_labels), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_graphs(history, string):\n",
    "  plt.plot(history.history[string])\n",
    "  plt.plot(history.history['val_'+string])\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(string)\n",
    "  plt.legend([string, 'val_'+string])\n",
    "  plt.show()\n",
    "\n",
    "plot_graphs(history, 'accuracy')\n",
    "plot_graphs(history, 'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"test.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import json\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "vocab_size = 1000\n",
    "embedding_dim = 16\n",
    "max_length = 120\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<OOV>\"\n",
    "training_size = 20000\n",
    "\n",
    "\n",
    "with open(\"./sarcasm.json\", 'r') as f:\n",
    "    datastore = json.load(f)\n",
    "\n",
    "\n",
    "sentences = []\n",
    "labels = []\n",
    "urls = []\n",
    "for item in datastore:\n",
    "    sentences.append(item['headline'])\n",
    "    labels.append(item['is_sarcastic'])\n",
    "\n",
    "training_sentences = sentences[0:training_size]\n",
    "testing_sentences = sentences[training_size:]\n",
    "training_labels = labels[0:training_size]\n",
    "testing_labels = labels[training_size:]\n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(training_sentences)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
    "training_padded = pad_sequences(training_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
    "testing_padded = pad_sequences(testing_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.Conv1D(128, 5, activation='relu'),\n",
    "    tf.keras.layers.GlobalMaxPooling1D(),\n",
    "    tf.keras.layers.Dense(24, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "num_epochs = 50\n",
    "\n",
    "training_padded = np.array(training_padded)\n",
    "training_labels = np.array(training_labels)\n",
    "testing_padded = np.array(testing_padded)\n",
    "testing_labels = np.array(testing_labels)\n",
    "history = model.fit(training_padded, training_labels, epochs=num_epochs, validation_data=(testing_padded, testing_labels), verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_graphs(history, string):\n",
    "  plt.plot(history.history[string])\n",
    "  plt.plot(history.history['val_'+string])\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(string)\n",
    "  plt.legend([string, 'val_'+string])\n",
    "  plt.show()\n",
    "\n",
    "plot_graphs(history, 'accuracy')\n",
    "plot_graphs(history, 'loss')\n",
    "model.save(\"test.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Sequence model and prediction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Week 4 - lab 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'and': 1, 'the': 2, 'a': 3, 'in': 4, 'all': 5, 'i': 6, 'for': 7, 'of': 8, 'lanigans': 9, 'ball': 10, 'were': 11, 'at': 12, 'to': 13, 'she': 14, 'stepped': 15, 'his': 16, 'girls': 17, 'as': 18, 'they': 19, 'til': 20, 'he': 21, 'again': 22, 'got': 23, 'boys': 24, 'round': 25, 'that': 26, 'her': 27, 'there': 28, 'three': 29, 'weeks': 30, 'up': 31, 'out': 32, 'him': 33, 'was': 34, 'spent': 35, 'learning': 36, 'new': 37, 'steps': 38, 'long': 39, 'away': 40, 'left': 41, 'friends': 42, 'relations': 43, 'when': 44, 'wall': 45, 'myself': 46, 'nice': 47, 'just': 48, 'dancing': 49, 'merry': 50, 'tipped': 51, 'me': 52, 'soon': 53, 'time': 54, 'old': 55, 'their': 56, 'them': 57, 'danced': 58, 'dublin': 59, 'an': 60, 'put': 61, 'leg': 62, 'miss': 63, 'fainted': 64, 'from': 65, 'town': 66, 'athy': 67, 'one': 68, 'jeremy': 69, 'lanigan': 70, 'battered': 71, 'hadnt': 72, 'pound': 73, 'father': 74, 'died': 75, 'made': 76, 'man': 77, 'farm': 78, 'ten': 79, 'acres': 80, 'ground': 81, 'gave': 82, 'grand': 83, 'party': 84, 'who': 85, 'didnt': 86, 'forget': 87, 'come': 88, 'if': 89, 'youll': 90, 'but': 91, 'listen': 92, 'ill': 93, 'make': 94, 'your': 95, 'eyes': 96, 'glisten': 97, 'rows': 98, 'ructions': 99, 'be': 100, 'sure': 101, 'free': 102, 'invitation': 103, 'might': 104, 'ask': 105, 'minute': 106, 'both': 107, 'bees': 108, 'cask': 109, 'judy': 110, 'odaly': 111, 'little': 112, 'milliner': 113, 'wink': 114, 'give': 115, 'call': 116, 'arrived': 117, 'with': 118, 'peggy': 119, 'mcgilligan': 120, 'lashings': 121, 'punch': 122, 'wine': 123, 'ladies': 124, 'potatoes': 125, 'cakes': 126, 'bacon': 127, 'tea': 128, 'nolans': 129, 'dolans': 130, 'ogradys': 131, 'courting': 132, 'songs': 133, 'went': 134, 'plenty': 135, 'water': 136, 'harp': 137, 'once': 138, 'sounded': 139, 'taras': 140, 'hall': 141, 'sweet': 142, 'nelly': 143, 'gray': 144, 'rat': 145, 'catchers': 146, 'daughter': 147, 'singing': 148, 'together': 149, 'doing': 150, 'kinds': 151, 'nonsensical': 152, 'polkas': 153, 'room': 154, 'whirligig': 155, 'julia': 156, 'we': 157, 'banished': 158, 'nonsense': 159, 'twist': 160, 'reel': 161, 'jig': 162, 'ach': 163, 'mavrone': 164, 'how': 165, 'mad': 166, 'youd': 167, 'think': 168, 'ceiling': 169, 'would': 170, 'fall': 171, 'brooks': 172, 'academy': 173, 'learn': 174, 'nothing': 175, 'hearty': 176, 'around': 177, 'couples': 178, 'groups': 179, 'accident': 180, 'happened': 181, 'young': 182, 'terrance': 183, 'mccarthy': 184, 'right': 185, 'through': 186, 'finnertys': 187, 'hoops': 188, 'poor': 189, 'creature': 190, 'cried': 191, 'meelia': 192, 'murther': 193, 'called': 194, 'brothers': 195, 'gathered': 196, 'carmody': 197, 'swore': 198, 'hed': 199, 'go': 200, 'no': 201, 'further': 202, 'had': 203, 'satisfaction': 204, 'midst': 205, 'row': 206, 'kerrigan': 207, 'cheeks': 208, 'same': 209, 'red': 210, 'rose': 211, 'some': 212, 'lads': 213, 'declared': 214, 'painted': 215, 'took': 216, 'small': 217, 'drop': 218, 'too': 219, 'much': 220, 'suppose': 221, 'sweetheart': 222, 'ned': 223, 'morgan': 224, 'so': 225, 'powerful': 226, 'able': 227, 'saw': 228, 'fair': 229, 'colleen': 230, 'stretched': 231, 'by': 232, 'tore': 233, 'under': 234, 'table': 235, 'smashed': 236, 'chaneys': 237, 'oh': 238, 'twas': 239, 'then': 240, 'runctions': 241, 'lick': 242, 'big': 243, 'phelim': 244, 'mchugh': 245, 'replied': 246, 'introduction': 247, 'kicked': 248, 'terrible': 249, 'hullabaloo': 250, 'casey': 251, 'piper': 252, 'near': 253, 'being': 254, 'strangled': 255, 'squeezed': 256, 'pipes': 257, 'bellows': 258, 'chanters': 259, 'ribbons': 260, 'entangled': 261, 'end': 262}\n",
      "263\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "\n",
    "data=\"In the town of Athy one Jeremy Lanigan \\n Battered away til he hadnt a pound. \\nHis father died and made him a man again \\n Left him a farm and ten acres of ground. \\nHe gave a grand party for friends and relations \\nWho didnt forget him when come to the wall, \\nAnd if youll but listen Ill make your eyes glisten \\nOf the rows and the ructions of Lanigans Ball. \\nMyself to be sure got free invitation, \\nFor all the nice girls and boys I might ask, \\nAnd just in a minute both friends and relations \\nWere dancing round merry as bees round a cask. \\nJudy ODaly, that nice little milliner, \\nShe tipped me a wink for to give her a call, \\nAnd I soon arrived with Peggy McGilligan \\nJust in time for Lanigans Ball. \\nThere were lashings of punch and wine for the ladies, \\nPotatoes and cakes; there was bacon and tea, \\nThere were the Nolans, Dolans, OGradys \\nCourting the girls and dancing away. \\nSongs they went round as plenty as water, \\nThe harp that once sounded in Taras old hall,\\nSweet Nelly Gray and The Rat Catchers Daughter,\\nAll singing together at Lanigans Ball. \\nThey were doing all kinds of nonsensical polkas \\nAll round the room in a whirligig. \\nJulia and I, we banished their nonsense \\nAnd tipped them the twist of a reel and a jig. \\nAch mavrone, how the girls got all mad at me \\nDanced til youd think the ceiling would fall. \\nFor I spent three weeks at Brooks Academy \\nLearning new steps for Lanigans Ball. \\nThree long weeks I spent up in Dublin, \\nThree long weeks to learn nothing at all,\\n Three long weeks I spent up in Dublin, \\nLearning new steps for Lanigans Ball. \\nShe stepped out and I stepped in again, \\nI stepped out and she stepped in again, \\nShe stepped out and I stepped in again, \\nLearning new steps for Lanigans Ball. \\nBoys were all merry and the girls they were hearty \\nAnd danced all around in couples and groups, \\nTil an accident happened, young Terrance McCarthy \\nPut his right leg through miss Finnertys hoops. \\nPoor creature fainted and cried Meelia murther, \\nCalled for her brothers and gathered them all. \\nCarmody swore that hed go no further \\nTil he had satisfaction at Lanigans Ball. \\nIn the midst of the row miss Kerrigan fainted, \\nHer cheeks at the same time as red as a rose. \\nSome of the lads declared she was painted, \\nShe took a small drop too much, I suppose. \\nHer sweetheart, Ned Morgan, so powerful and able, \\nWhen he saw his fair colleen stretched out by the wall, \\nTore the left leg from under the table \\nAnd smashed all the Chaneys at Lanigans Ball. \\nBoys, oh boys, twas then there were runctions. \\nMyself got a lick from big Phelim McHugh. \\nI soon replied to his introduction \\nAnd kicked up a terrible hullabaloo. \\nOld Casey, the piper, was near being strangled. \\nThey squeezed up his pipes, bellows, chanters and all. \\nThe girls, in their ribbons, they got all entangled \\nAnd that put an end to Lanigans Ball.\"\n",
    "\n",
    "corpus = data.lower().split(\"\\n\")\n",
    "\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "print(tokenizer.word_index)\n",
    "print(total_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences = []\n",
    "for line in corpus:\n",
    "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
    "\tfor i in range(1, len(token_list)):\n",
    "\t\tn_gram_sequence = token_list[:i+1]\n",
    "\t\tinput_sequences.append(n_gram_sequence)\n",
    "\n",
    "# pad sequences \n",
    "max_sequence_len = max([len(x) for x in input_sequences])\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "\n",
    "# create predictors and label\n",
    "xs, labels = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "\n",
    "ys = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "2\n",
      "66\n",
      "8\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.word_index['in'])\n",
    "print(tokenizer.word_index['the'])\n",
    "print(tokenizer.word_index['town'])\n",
    "print(tokenizer.word_index['of'])\n",
    "print(tokenizer.word_index['athy'])\n",
    "print(tokenizer.word_index['one'])\n",
    "print(tokenizer.word_index['jeremy'])\n",
    "print(tokenizer.word_index['lanigan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  0  0  0  4  2 66  8 67 68]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[ 0  0  0  4  2 66  8 67 68 69]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(xs[5])\n",
    "print(ys[5])\n",
    "print(xs[6])\n",
    "print(ys[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'and': 1, 'the': 2, 'a': 3, 'in': 4, 'all': 5, 'i': 6, 'for': 7, 'of': 8, 'lanigans': 9, 'ball': 10, 'were': 11, 'at': 12, 'to': 13, 'she': 14, 'stepped': 15, 'his': 16, 'girls': 17, 'as': 18, 'they': 19, 'til': 20, 'he': 21, 'again': 22, 'got': 23, 'boys': 24, 'round': 25, 'that': 26, 'her': 27, 'there': 28, 'three': 29, 'weeks': 30, 'up': 31, 'out': 32, 'him': 33, 'was': 34, 'spent': 35, 'learning': 36, 'new': 37, 'steps': 38, 'long': 39, 'away': 40, 'left': 41, 'friends': 42, 'relations': 43, 'when': 44, 'wall': 45, 'myself': 46, 'nice': 47, 'just': 48, 'dancing': 49, 'merry': 50, 'tipped': 51, 'me': 52, 'soon': 53, 'time': 54, 'old': 55, 'their': 56, 'them': 57, 'danced': 58, 'dublin': 59, 'an': 60, 'put': 61, 'leg': 62, 'miss': 63, 'fainted': 64, 'from': 65, 'town': 66, 'athy': 67, 'one': 68, 'jeremy': 69, 'lanigan': 70, 'battered': 71, 'hadnt': 72, 'pound': 73, 'father': 74, 'died': 75, 'made': 76, 'man': 77, 'farm': 78, 'ten': 79, 'acres': 80, 'ground': 81, 'gave': 82, 'grand': 83, 'party': 84, 'who': 85, 'didnt': 86, 'forget': 87, 'come': 88, 'if': 89, 'youll': 90, 'but': 91, 'listen': 92, 'ill': 93, 'make': 94, 'your': 95, 'eyes': 96, 'glisten': 97, 'rows': 98, 'ructions': 99, 'be': 100, 'sure': 101, 'free': 102, 'invitation': 103, 'might': 104, 'ask': 105, 'minute': 106, 'both': 107, 'bees': 108, 'cask': 109, 'judy': 110, 'odaly': 111, 'little': 112, 'milliner': 113, 'wink': 114, 'give': 115, 'call': 116, 'arrived': 117, 'with': 118, 'peggy': 119, 'mcgilligan': 120, 'lashings': 121, 'punch': 122, 'wine': 123, 'ladies': 124, 'potatoes': 125, 'cakes': 126, 'bacon': 127, 'tea': 128, 'nolans': 129, 'dolans': 130, 'ogradys': 131, 'courting': 132, 'songs': 133, 'went': 134, 'plenty': 135, 'water': 136, 'harp': 137, 'once': 138, 'sounded': 139, 'taras': 140, 'hall': 141, 'sweet': 142, 'nelly': 143, 'gray': 144, 'rat': 145, 'catchers': 146, 'daughter': 147, 'singing': 148, 'together': 149, 'doing': 150, 'kinds': 151, 'nonsensical': 152, 'polkas': 153, 'room': 154, 'whirligig': 155, 'julia': 156, 'we': 157, 'banished': 158, 'nonsense': 159, 'twist': 160, 'reel': 161, 'jig': 162, 'ach': 163, 'mavrone': 164, 'how': 165, 'mad': 166, 'youd': 167, 'think': 168, 'ceiling': 169, 'would': 170, 'fall': 171, 'brooks': 172, 'academy': 173, 'learn': 174, 'nothing': 175, 'hearty': 176, 'around': 177, 'couples': 178, 'groups': 179, 'accident': 180, 'happened': 181, 'young': 182, 'terrance': 183, 'mccarthy': 184, 'right': 185, 'through': 186, 'finnertys': 187, 'hoops': 188, 'poor': 189, 'creature': 190, 'cried': 191, 'meelia': 192, 'murther': 193, 'called': 194, 'brothers': 195, 'gathered': 196, 'carmody': 197, 'swore': 198, 'hed': 199, 'go': 200, 'no': 201, 'further': 202, 'had': 203, 'satisfaction': 204, 'midst': 205, 'row': 206, 'kerrigan': 207, 'cheeks': 208, 'same': 209, 'red': 210, 'rose': 211, 'some': 212, 'lads': 213, 'declared': 214, 'painted': 215, 'took': 216, 'small': 217, 'drop': 218, 'too': 219, 'much': 220, 'suppose': 221, 'sweetheart': 222, 'ned': 223, 'morgan': 224, 'so': 225, 'powerful': 226, 'able': 227, 'saw': 228, 'fair': 229, 'colleen': 230, 'stretched': 231, 'by': 232, 'tore': 233, 'under': 234, 'table': 235, 'smashed': 236, 'chaneys': 237, 'oh': 238, 'twas': 239, 'then': 240, 'runctions': 241, 'lick': 242, 'big': 243, 'phelim': 244, 'mchugh': 245, 'replied': 246, 'introduction': 247, 'kicked': 248, 'terrible': 249, 'hullabaloo': 250, 'casey': 251, 'piper': 252, 'near': 253, 'being': 254, 'strangled': 255, 'squeezed': 256, 'pipes': 257, 'bellows': 258, 'chanters': 259, 'ribbons': 260, 'entangled': 261, 'end': 262}\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 5.5688 - accuracy: 0.0155\n",
      "Epoch 2/500\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 5.5452 - accuracy: 0.0552\n",
      "Epoch 3/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 5.4903 - accuracy: 0.0552\n",
      "Epoch 4/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 5.3280 - accuracy: 0.0464\n",
      "Epoch 5/500\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 5.1366 - accuracy: 0.0486\n",
      "Epoch 6/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 5.0782 - accuracy: 0.0331\n",
      "Epoch 7/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 5.0402 - accuracy: 0.0508\n",
      "Epoch 8/500\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 5.0124 - accuracy: 0.0508\n",
      "Epoch 9/500\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 4.9863 - accuracy: 0.0486\n",
      "Epoch 10/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 4.9573 - accuracy: 0.0596\n",
      "Epoch 11/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 4.9205 - accuracy: 0.0552\n",
      "Epoch 12/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 4.8834 - accuracy: 0.0574\n",
      "Epoch 13/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 4.8483 - accuracy: 0.0530\n",
      "Epoch 14/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 4.8007 - accuracy: 0.0508\n",
      "Epoch 15/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 4.7564 - accuracy: 0.0640\n",
      "Epoch 16/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 4.7074 - accuracy: 0.0751\n",
      "Epoch 17/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 4.6615 - accuracy: 0.0662\n",
      "Epoch 18/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 4.6164 - accuracy: 0.0817\n",
      "Epoch 19/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 4.5840 - accuracy: 0.0795\n",
      "Epoch 20/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 4.5419 - accuracy: 0.0883\n",
      "Epoch 21/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 4.5026 - accuracy: 0.0883\n",
      "Epoch 22/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 4.4618 - accuracy: 0.0949\n",
      "Epoch 23/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 4.4269 - accuracy: 0.0927\n",
      "Epoch 24/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 4.3841 - accuracy: 0.0993\n",
      "Epoch 25/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 4.3389 - accuracy: 0.1015\n",
      "Epoch 26/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 4.3018 - accuracy: 0.1038\n",
      "Epoch 27/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 4.2551 - accuracy: 0.1082\n",
      "Epoch 28/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 4.2117 - accuracy: 0.1148\n",
      "Epoch 29/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 4.1719 - accuracy: 0.1148\n",
      "Epoch 30/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 4.1152 - accuracy: 0.1302\n",
      "Epoch 31/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 4.0708 - accuracy: 0.1347\n",
      "Epoch 32/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 4.0241 - accuracy: 0.1413\n",
      "Epoch 33/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 3.9690 - accuracy: 0.1634\n",
      "Epoch 34/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 3.9238 - accuracy: 0.1634\n",
      "Epoch 35/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 3.8679 - accuracy: 0.1744\n",
      "Epoch 36/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 3.8327 - accuracy: 0.1832\n",
      "Epoch 37/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 3.7847 - accuracy: 0.1943\n",
      "Epoch 38/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 3.7349 - accuracy: 0.2185\n",
      "Epoch 39/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 3.6871 - accuracy: 0.2119\n",
      "Epoch 40/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 3.6451 - accuracy: 0.2296\n",
      "Epoch 41/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 3.5970 - accuracy: 0.2406\n",
      "Epoch 42/500\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 3.5501 - accuracy: 0.2472\n",
      "Epoch 43/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 3.5085 - accuracy: 0.2781\n",
      "Epoch 44/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 3.4750 - accuracy: 0.2804\n",
      "Epoch 45/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 3.4636 - accuracy: 0.2693\n",
      "Epoch 46/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 3.4307 - accuracy: 0.2826\n",
      "Epoch 47/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 3.3732 - accuracy: 0.2980\n",
      "Epoch 48/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 3.3142 - accuracy: 0.2958\n",
      "Epoch 49/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 3.2776 - accuracy: 0.3223\n",
      "Epoch 50/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 3.2611 - accuracy: 0.3179\n",
      "Epoch 51/500\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 3.2236 - accuracy: 0.3289\n",
      "Epoch 52/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 3.1738 - accuracy: 0.3400\n",
      "Epoch 53/500\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 3.1285 - accuracy: 0.3753\n",
      "Epoch 54/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 3.0882 - accuracy: 0.3753\n",
      "Epoch 55/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 3.0488 - accuracy: 0.3731\n",
      "Epoch 56/500\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 3.0081 - accuracy: 0.3819\n",
      "Epoch 57/500\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 2.9841 - accuracy: 0.3929\n",
      "Epoch 58/500\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 2.9535 - accuracy: 0.4040\n",
      "Epoch 59/500\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 2.9176 - accuracy: 0.4238\n",
      "Epoch 60/500\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 2.8707 - accuracy: 0.4238\n",
      "Epoch 61/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 2.8345 - accuracy: 0.4371\n",
      "Epoch 62/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 2.7960 - accuracy: 0.4415\n",
      "Epoch 63/500\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 2.7687 - accuracy: 0.4547\n",
      "Epoch 64/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 2.7388 - accuracy: 0.4658\n",
      "Epoch 65/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 2.7147 - accuracy: 0.4636\n",
      "Epoch 66/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 2.7096 - accuracy: 0.4614\n",
      "Epoch 67/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 2.6675 - accuracy: 0.4879\n",
      "Epoch 68/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 2.6332 - accuracy: 0.4967\n",
      "Epoch 69/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 2.6052 - accuracy: 0.5077\n",
      "Epoch 70/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 2.5692 - accuracy: 0.5143\n",
      "Epoch 71/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 2.5326 - accuracy: 0.5188\n",
      "Epoch 72/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 2.5054 - accuracy: 0.5143\n",
      "Epoch 73/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 2.4789 - accuracy: 0.5342\n",
      "Epoch 74/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 2.4545 - accuracy: 0.5342\n",
      "Epoch 75/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 2.4377 - accuracy: 0.5342\n",
      "Epoch 76/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 2.4134 - accuracy: 0.5342: 0s - loss: 2.3509 - accuracy: 0.\n",
      "Epoch 77/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 2.3829 - accuracy: 0.5541\n",
      "Epoch 78/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 2.3533 - accuracy: 0.5607\n",
      "Epoch 79/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 2.3294 - accuracy: 0.5762\n",
      "Epoch 80/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 2.3277 - accuracy: 0.5828\n",
      "Epoch 81/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 2.2906 - accuracy: 0.5894\n",
      "Epoch 82/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 2.2628 - accuracy: 0.5828\n",
      "Epoch 83/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 2.2394 - accuracy: 0.5894: 0s - loss: 2.2394 - accuracy: 0.58\n",
      "Epoch 84/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 2.2197 - accuracy: 0.5938\n",
      "Epoch 85/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 2.1853 - accuracy: 0.6203\n",
      "Epoch 86/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 2.1536 - accuracy: 0.6181\n",
      "Epoch 87/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 2.1508 - accuracy: 0.6026\n",
      "Epoch 88/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 2.1219 - accuracy: 0.6137\n",
      "Epoch 89/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 2.0863 - accuracy: 0.6468\n",
      "Epoch 90/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 2.0688 - accuracy: 0.6424\n",
      "Epoch 91/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 2.0513 - accuracy: 0.6358: 0s - loss: 2.0522 - accuracy: 0.64\n",
      "Epoch 92/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 2.0442 - accuracy: 0.6380\n",
      "Epoch 93/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 2.0290 - accuracy: 0.6446\n",
      "Epoch 94/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.9944 - accuracy: 0.6623\n",
      "Epoch 95/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 1.9721 - accuracy: 0.6667\n",
      "Epoch 96/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 1.9422 - accuracy: 0.6733\n",
      "Epoch 97/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 1.9250 - accuracy: 0.6755\n",
      "Epoch 98/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 1.8988 - accuracy: 0.6843\n",
      "Epoch 99/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 1.8875 - accuracy: 0.6865\n",
      "Epoch 100/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 1.8755 - accuracy: 0.6799\n",
      "Epoch 101/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.8548 - accuracy: 0.6777\n",
      "Epoch 102/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 1.8458 - accuracy: 0.6843\n",
      "Epoch 103/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.8129 - accuracy: 0.6909\n",
      "Epoch 104/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 1.7809 - accuracy: 0.7064\n",
      "Epoch 105/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 1.7707 - accuracy: 0.6976\n",
      "Epoch 106/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 1.7474 - accuracy: 0.7152\n",
      "Epoch 107/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 1.7343 - accuracy: 0.7263\n",
      "Epoch 108/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.7212 - accuracy: 0.7130\n",
      "Epoch 109/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.7367 - accuracy: 0.7020\n",
      "Epoch 110/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.6988 - accuracy: 0.7219\n",
      "Epoch 111/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 1.6851 - accuracy: 0.7152\n",
      "Epoch 112/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 1.6717 - accuracy: 0.7196\n",
      "Epoch 113/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 1.6467 - accuracy: 0.7307\n",
      "Epoch 114/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 1.6298 - accuracy: 0.7395\n",
      "Epoch 115/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.6009 - accuracy: 0.7506\n",
      "Epoch 116/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 1.6034 - accuracy: 0.7461\n",
      "Epoch 117/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 1.5791 - accuracy: 0.7373\n",
      "Epoch 118/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.5563 - accuracy: 0.7528\n",
      "Epoch 119/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.5343 - accuracy: 0.7572\n",
      "Epoch 120/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.5106 - accuracy: 0.7638\n",
      "Epoch 121/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 1.4912 - accuracy: 0.7660\n",
      "Epoch 122/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 1.4807 - accuracy: 0.7748\n",
      "Epoch 123/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 1.4598 - accuracy: 0.7837\n",
      "Epoch 124/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.4409 - accuracy: 0.7859\n",
      "Epoch 125/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.4205 - accuracy: 0.7881\n",
      "Epoch 126/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.4081 - accuracy: 0.7859\n",
      "Epoch 127/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.3966 - accuracy: 0.7903\n",
      "Epoch 128/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.3755 - accuracy: 0.7925\n",
      "Epoch 129/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.3624 - accuracy: 0.7925\n",
      "Epoch 130/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.3413 - accuracy: 0.7969\n",
      "Epoch 131/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 1.3371 - accuracy: 0.7969\n",
      "Epoch 132/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.3319 - accuracy: 0.7903\n",
      "Epoch 133/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.3439 - accuracy: 0.8013\n",
      "Epoch 134/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 1.3828 - accuracy: 0.7704\n",
      "Epoch 135/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 1.3576 - accuracy: 0.7881\n",
      "Epoch 136/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 1.3180 - accuracy: 0.7925\n",
      "Epoch 137/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.2846 - accuracy: 0.7991: 0s - loss: 1.2890 - accuracy: 0.80\n",
      "Epoch 138/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 1.2632 - accuracy: 0.8146\n",
      "Epoch 139/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.2497 - accuracy: 0.8146\n",
      "Epoch 140/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.2359 - accuracy: 0.8190\n",
      "Epoch 141/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.2167 - accuracy: 0.8168\n",
      "Epoch 142/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.1989 - accuracy: 0.8256\n",
      "Epoch 143/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.1848 - accuracy: 0.8234\n",
      "Epoch 144/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.1769 - accuracy: 0.8300\n",
      "Epoch 145/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.2369 - accuracy: 0.8013\n",
      "Epoch 146/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.2350 - accuracy: 0.8079\n",
      "Epoch 147/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.2171 - accuracy: 0.8168\n",
      "Epoch 148/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.2030 - accuracy: 0.8300\n",
      "Epoch 149/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.2236 - accuracy: 0.8146\n",
      "Epoch 150/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 1.1937 - accuracy: 0.8300\n",
      "Epoch 151/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.1663 - accuracy: 0.8366\n",
      "Epoch 152/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 1.1358 - accuracy: 0.8300\n",
      "Epoch 153/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.1048 - accuracy: 0.8366\n",
      "Epoch 154/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.0847 - accuracy: 0.8587\n",
      "Epoch 155/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 1.0707 - accuracy: 0.8543\n",
      "Epoch 156/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.0562 - accuracy: 0.8609\n",
      "Epoch 157/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.0425 - accuracy: 0.8587\n",
      "Epoch 158/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.0281 - accuracy: 0.8653\n",
      "Epoch 159/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.0209 - accuracy: 0.8675\n",
      "Epoch 160/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.0080 - accuracy: 0.8742\n",
      "Epoch 161/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.9946 - accuracy: 0.8742\n",
      "Epoch 162/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.9854 - accuracy: 0.8675\n",
      "Epoch 163/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.9718 - accuracy: 0.8742\n",
      "Epoch 164/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.9608 - accuracy: 0.8675\n",
      "Epoch 165/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.9512 - accuracy: 0.8764\n",
      "Epoch 166/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.9403 - accuracy: 0.8720\n",
      "Epoch 167/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.9330 - accuracy: 0.8764\n",
      "Epoch 168/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.9243 - accuracy: 0.8764\n",
      "Epoch 169/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.9140 - accuracy: 0.8764\n",
      "Epoch 170/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.9067 - accuracy: 0.8808\n",
      "Epoch 171/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.8932 - accuracy: 0.8962\n",
      "Epoch 172/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.8830 - accuracy: 0.8940\n",
      "Epoch 173/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.8745 - accuracy: 0.8852\n",
      "Epoch 174/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.8637 - accuracy: 0.9007\n",
      "Epoch 175/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.8562 - accuracy: 0.8896\n",
      "Epoch 176/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.8493 - accuracy: 0.8874\n",
      "Epoch 177/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.8446 - accuracy: 0.8852\n",
      "Epoch 178/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.8305 - accuracy: 0.8852\n",
      "Epoch 179/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.8225 - accuracy: 0.8918\n",
      "Epoch 180/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.8118 - accuracy: 0.9007\n",
      "Epoch 181/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.8061 - accuracy: 0.9007\n",
      "Epoch 182/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.7989 - accuracy: 0.9095\n",
      "Epoch 183/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.7922 - accuracy: 0.9117\n",
      "Epoch 184/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.7824 - accuracy: 0.9139\n",
      "Epoch 185/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.7757 - accuracy: 0.9161\n",
      "Epoch 186/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.7671 - accuracy: 0.9095\n",
      "Epoch 187/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.7593 - accuracy: 0.9095\n",
      "Epoch 188/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.7516 - accuracy: 0.9095\n",
      "Epoch 189/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.7439 - accuracy: 0.9139\n",
      "Epoch 190/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.7368 - accuracy: 0.9095\n",
      "Epoch 191/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.7300 - accuracy: 0.9073\n",
      "Epoch 192/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.7249 - accuracy: 0.9117\n",
      "Epoch 193/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.7169 - accuracy: 0.9161\n",
      "Epoch 194/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.7089 - accuracy: 0.9183\n",
      "Epoch 195/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.7038 - accuracy: 0.9161\n",
      "Epoch 196/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.7071 - accuracy: 0.9139\n",
      "Epoch 197/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.6984 - accuracy: 0.9183\n",
      "Epoch 198/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.6923 - accuracy: 0.9249\n",
      "Epoch 199/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.6826 - accuracy: 0.9227\n",
      "Epoch 200/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6747 - accuracy: 0.9227\n",
      "Epoch 201/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.6664 - accuracy: 0.9183\n",
      "Epoch 202/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6608 - accuracy: 0.9294\n",
      "Epoch 203/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6529 - accuracy: 0.9205\n",
      "Epoch 204/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6453 - accuracy: 0.9227\n",
      "Epoch 205/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.6456 - accuracy: 0.9227\n",
      "Epoch 206/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.6339 - accuracy: 0.9205\n",
      "Epoch 207/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.6291 - accuracy: 0.9205\n",
      "Epoch 208/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.6212 - accuracy: 0.9272\n",
      "Epoch 209/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.6179 - accuracy: 0.9316\n",
      "Epoch 210/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.6114 - accuracy: 0.9338\n",
      "Epoch 211/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6067 - accuracy: 0.9338\n",
      "Epoch 212/500\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.6414 - accuracy: 0.91 - 0s 6ms/step - loss: 0.6028 - accuracy: 0.9338\n",
      "Epoch 213/500\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.5973 - accuracy: 0.93 - 0s 8ms/step - loss: 0.5965 - accuracy: 0.9316\n",
      "Epoch 214/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5931 - accuracy: 0.9316\n",
      "Epoch 215/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5882 - accuracy: 0.9338\n",
      "Epoch 216/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5850 - accuracy: 0.9316: 0s - loss: 0.5845 - accuracy: 0.93\n",
      "Epoch 217/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.5798 - accuracy: 0.9338\n",
      "Epoch 218/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5730 - accuracy: 0.9360\n",
      "Epoch 219/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.5674 - accuracy: 0.9338\n",
      "Epoch 220/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.5605 - accuracy: 0.9360\n",
      "Epoch 221/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.5571 - accuracy: 0.9360\n",
      "Epoch 222/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.5509 - accuracy: 0.9360\n",
      "Epoch 223/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.5504 - accuracy: 0.9360\n",
      "Epoch 224/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.5416 - accuracy: 0.9316\n",
      "Epoch 225/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.5372 - accuracy: 0.9338\n",
      "Epoch 226/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.5295 - accuracy: 0.9360\n",
      "Epoch 227/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5256 - accuracy: 0.9360\n",
      "Epoch 228/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.5234 - accuracy: 0.9338\n",
      "Epoch 229/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5178 - accuracy: 0.9360\n",
      "Epoch 230/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5126 - accuracy: 0.9360\n",
      "Epoch 231/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.5087 - accuracy: 0.9360\n",
      "Epoch 232/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.5053 - accuracy: 0.9404\n",
      "Epoch 233/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.5042 - accuracy: 0.9294\n",
      "Epoch 234/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.5075 - accuracy: 0.9294\n",
      "Epoch 235/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.5129 - accuracy: 0.9316\n",
      "Epoch 236/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5217 - accuracy: 0.9227\n",
      "Epoch 237/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5263 - accuracy: 0.9272\n",
      "Epoch 238/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.5383 - accuracy: 0.9161\n",
      "Epoch 239/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.5420 - accuracy: 0.9073\n",
      "Epoch 240/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.5834 - accuracy: 0.8896\n",
      "Epoch 241/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5389 - accuracy: 0.9183\n",
      "Epoch 242/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5377 - accuracy: 0.9227\n",
      "Epoch 243/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.5194 - accuracy: 0.9294\n",
      "Epoch 244/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5039 - accuracy: 0.9249\n",
      "Epoch 245/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.4872 - accuracy: 0.9316\n",
      "Epoch 246/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4870 - accuracy: 0.9338\n",
      "Epoch 247/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5728 - accuracy: 0.9139\n",
      "Epoch 248/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6002 - accuracy: 0.8985\n",
      "Epoch 249/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6256 - accuracy: 0.8830\n",
      "Epoch 250/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5792 - accuracy: 0.8896\n",
      "Epoch 251/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.5314 - accuracy: 0.9161\n",
      "Epoch 252/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.5138 - accuracy: 0.9117\n",
      "Epoch 253/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.5296 - accuracy: 0.9029\n",
      "Epoch 254/500\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.4853 - accuracy: 0.9272\n",
      "Epoch 255/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.4665 - accuracy: 0.9316\n",
      "Epoch 256/500\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.4536 - accuracy: 0.9316\n",
      "Epoch 257/500\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.4364 - accuracy: 0.9382\n",
      "Epoch 258/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4272 - accuracy: 0.9360\n",
      "Epoch 259/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.4226 - accuracy: 0.9404\n",
      "Epoch 260/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4145 - accuracy: 0.9404\n",
      "Epoch 261/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.4082 - accuracy: 0.9360\n",
      "Epoch 262/500\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.4029 - accuracy: 0.9382\n",
      "Epoch 263/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.3996 - accuracy: 0.9426\n",
      "Epoch 264/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.3965 - accuracy: 0.9426\n",
      "Epoch 265/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.3942 - accuracy: 0.9448\n",
      "Epoch 266/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.3918 - accuracy: 0.9404\n",
      "Epoch 267/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.3879 - accuracy: 0.9426\n",
      "Epoch 268/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3841 - accuracy: 0.9404\n",
      "Epoch 269/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3802 - accuracy: 0.9448\n",
      "Epoch 270/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.3773 - accuracy: 0.9426\n",
      "Epoch 271/500\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.3740 - accuracy: 0.9470\n",
      "Epoch 272/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.3709 - accuracy: 0.9448\n",
      "Epoch 273/500\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.3683 - accuracy: 0.9448\n",
      "Epoch 274/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.3654 - accuracy: 0.9448\n",
      "Epoch 275/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3645 - accuracy: 0.9404\n",
      "Epoch 276/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3606 - accuracy: 0.9492\n",
      "Epoch 277/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3600 - accuracy: 0.9492\n",
      "Epoch 278/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3560 - accuracy: 0.9426\n",
      "Epoch 279/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3518 - accuracy: 0.9492\n",
      "Epoch 280/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3495 - accuracy: 0.9470\n",
      "Epoch 281/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.3471 - accuracy: 0.9492\n",
      "Epoch 282/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3449 - accuracy: 0.9514\n",
      "Epoch 283/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3436 - accuracy: 0.9470\n",
      "Epoch 284/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3400 - accuracy: 0.9536\n",
      "Epoch 285/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.3392 - accuracy: 0.9470\n",
      "Epoch 286/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.3363 - accuracy: 0.9514\n",
      "Epoch 287/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.3332 - accuracy: 0.9492\n",
      "Epoch 288/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.3376 - accuracy: 0.9448\n",
      "Epoch 289/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.3309 - accuracy: 0.9448\n",
      "Epoch 290/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.3278 - accuracy: 0.9492\n",
      "Epoch 291/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.3246 - accuracy: 0.9448\n",
      "Epoch 292/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3245 - accuracy: 0.9448\n",
      "Epoch 293/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.3193 - accuracy: 0.9470\n",
      "Epoch 294/500\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.3182 - accuracy: 0.9426\n",
      "Epoch 295/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.3155 - accuracy: 0.9448\n",
      "Epoch 296/500\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.3141 - accuracy: 0.9426\n",
      "Epoch 297/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.3128 - accuracy: 0.9470\n",
      "Epoch 298/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.3101 - accuracy: 0.9448\n",
      "Epoch 299/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.3080 - accuracy: 0.9492\n",
      "Epoch 300/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.3053 - accuracy: 0.9448\n",
      "Epoch 301/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.3029 - accuracy: 0.9448\n",
      "Epoch 302/500\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.3022 - accuracy: 0.9448\n",
      "Epoch 303/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3002 - accuracy: 0.9470\n",
      "Epoch 304/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.2987 - accuracy: 0.9448\n",
      "Epoch 305/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.2972 - accuracy: 0.9492\n",
      "Epoch 306/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.2951 - accuracy: 0.9492\n",
      "Epoch 307/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.2928 - accuracy: 0.9492\n",
      "Epoch 308/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2916 - accuracy: 0.9470\n",
      "Epoch 309/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2899 - accuracy: 0.9470\n",
      "Epoch 310/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.2875 - accuracy: 0.9470\n",
      "Epoch 311/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.2861 - accuracy: 0.9492\n",
      "Epoch 312/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.2854 - accuracy: 0.9492\n",
      "Epoch 313/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2844 - accuracy: 0.9492\n",
      "Epoch 314/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.2813 - accuracy: 0.9470\n",
      "Epoch 315/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.2805 - accuracy: 0.9514\n",
      "Epoch 316/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.2790 - accuracy: 0.9492\n",
      "Epoch 317/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2775 - accuracy: 0.9470\n",
      "Epoch 318/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.2774 - accuracy: 0.9536\n",
      "Epoch 319/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2751 - accuracy: 0.9448\n",
      "Epoch 320/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2717 - accuracy: 0.9492\n",
      "Epoch 321/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2687 - accuracy: 0.9514\n",
      "Epoch 322/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2674 - accuracy: 0.9514\n",
      "Epoch 323/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2654 - accuracy: 0.9492\n",
      "Epoch 324/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.2676 - accuracy: 0.9492\n",
      "Epoch 325/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2663 - accuracy: 0.9470\n",
      "Epoch 326/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2625 - accuracy: 0.9470\n",
      "Epoch 327/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.2607 - accuracy: 0.9470\n",
      "Epoch 328/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.2579 - accuracy: 0.9492\n",
      "Epoch 329/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2564 - accuracy: 0.9470\n",
      "Epoch 330/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2550 - accuracy: 0.9470\n",
      "Epoch 331/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2545 - accuracy: 0.9426\n",
      "Epoch 332/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2523 - accuracy: 0.9448\n",
      "Epoch 333/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.2523 - accuracy: 0.9426\n",
      "Epoch 334/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2500 - accuracy: 0.9470\n",
      "Epoch 335/500\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.2487 - accuracy: 0.9470\n",
      "Epoch 336/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.2474 - accuracy: 0.9448\n",
      "Epoch 337/500\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.2468 - accuracy: 0.9448\n",
      "Epoch 338/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.2441 - accuracy: 0.9448\n",
      "Epoch 339/500\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.2453 - accuracy: 0.94 - 0s 13ms/step - loss: 0.2434 - accuracy: 0.9448\n",
      "Epoch 340/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.2419 - accuracy: 0.9404\n",
      "Epoch 341/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.2421 - accuracy: 0.9448\n",
      "Epoch 342/500\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.2386 - accuracy: 0.9514\n",
      "Epoch 343/500\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.2400 - accuracy: 0.9448\n",
      "Epoch 344/500\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.2384 - accuracy: 0.9426 0s - loss: 0.2457 - accuracy: 0.\n",
      "Epoch 345/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.2358 - accuracy: 0.9448\n",
      "Epoch 346/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.2347 - accuracy: 0.9448\n",
      "Epoch 347/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2331 - accuracy: 0.9470\n",
      "Epoch 348/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.2318 - accuracy: 0.9448\n",
      "Epoch 349/500\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.2318 - accuracy: 0.9426 0s - loss: 0.2261 - accuracy: \n",
      "Epoch 350/500\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.2295 - accuracy: 0.9448\n",
      "Epoch 351/500\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.2292 - accuracy: 0.9492 0s - loss: 0.2292 - accuracy: 0.94\n",
      "Epoch 352/500\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.2280 - accuracy: 0.9470\n",
      "Epoch 353/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.2265 - accuracy: 0.9492\n",
      "Epoch 354/500\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.2254 - accuracy: 0.9470\n",
      "Epoch 355/500\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.2243 - accuracy: 0.9492\n",
      "Epoch 356/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.2232 - accuracy: 0.9470\n",
      "Epoch 357/500\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.2218 - accuracy: 0.9492\n",
      "Epoch 358/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.2210 - accuracy: 0.9492\n",
      "Epoch 359/500\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.2200 - accuracy: 0.9426\n",
      "Epoch 360/500\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.2184 - accuracy: 0.9514 0s - loss: 0.1875 - accuracy\n",
      "Epoch 361/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.2180 - accuracy: 0.9470\n",
      "Epoch 362/500\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.2166 - accuracy: 0.9448\n",
      "Epoch 363/500\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.2156 - accuracy: 0.9470\n",
      "Epoch 364/500\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.2142 - accuracy: 0.9448\n",
      "Epoch 365/500\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.2131 - accuracy: 0.9448\n",
      "Epoch 366/500\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.2125 - accuracy: 0.9492\n",
      "Epoch 367/500\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.2149 - accuracy: 0.9448\n",
      "Epoch 368/500\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.2122 - accuracy: 0.9470 0s - loss: 0.1859 - accuracy: \n",
      "Epoch 369/500\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.2095 - accuracy: 0.9514\n",
      "Epoch 370/500\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.2083 - accuracy: 0.9514\n",
      "Epoch 371/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.2070 - accuracy: 0.9536\n",
      "Epoch 372/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.2073 - accuracy: 0.9404\n",
      "Epoch 373/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.2088 - accuracy: 0.9470 0s - loss: 0.2104 - accuracy: 0.94\n",
      "Epoch 374/500\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.2128 - accuracy: 0.9470 0s - loss: 0.2222 - accuracy: 0.\n",
      "Epoch 375/500\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.2266 - accuracy: 0.9492\n",
      "Epoch 376/500\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.2524 - accuracy: 0.9426\n",
      "Epoch 377/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.2358 - accuracy: 0.9448\n",
      "Epoch 378/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2496 - accuracy: 0.9382\n",
      "Epoch 379/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.2703 - accuracy: 0.9294\n",
      "Epoch 380/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3143 - accuracy: 0.9161\n",
      "Epoch 381/500\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.3825 - accuracy: 0.8985\n",
      "Epoch 382/500\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.3331 - accuracy: 0.9205\n",
      "Epoch 383/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.3036 - accuracy: 0.9272\n",
      "Epoch 384/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.3263 - accuracy: 0.9227\n",
      "Epoch 385/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3031 - accuracy: 0.9294\n",
      "Epoch 386/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.3235 - accuracy: 0.9316\n",
      "Epoch 387/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2720 - accuracy: 0.9382\n",
      "Epoch 388/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.2589 - accuracy: 0.9382\n",
      "Epoch 389/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.2475 - accuracy: 0.9382\n",
      "Epoch 390/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.2351 - accuracy: 0.9426\n",
      "Epoch 391/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.2335 - accuracy: 0.9448\n",
      "Epoch 392/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.2323 - accuracy: 0.9448\n",
      "Epoch 393/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.2247 - accuracy: 0.9470\n",
      "Epoch 394/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.2208 - accuracy: 0.9448\n",
      "Epoch 395/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2143 - accuracy: 0.9536\n",
      "Epoch 396/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2090 - accuracy: 0.9492\n",
      "Epoch 397/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2065 - accuracy: 0.9492\n",
      "Epoch 398/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2039 - accuracy: 0.9448\n",
      "Epoch 399/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2014 - accuracy: 0.9514\n",
      "Epoch 400/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2002 - accuracy: 0.9492\n",
      "Epoch 401/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1979 - accuracy: 0.9492\n",
      "Epoch 402/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1982 - accuracy: 0.9514\n",
      "Epoch 403/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1958 - accuracy: 0.9536\n",
      "Epoch 404/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1940 - accuracy: 0.9470\n",
      "Epoch 405/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1929 - accuracy: 0.9492\n",
      "Epoch 406/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.1916 - accuracy: 0.9448\n",
      "Epoch 407/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1899 - accuracy: 0.9492\n",
      "Epoch 408/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1895 - accuracy: 0.9514\n",
      "Epoch 409/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1876 - accuracy: 0.9536\n",
      "Epoch 410/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.1872 - accuracy: 0.9470\n",
      "Epoch 411/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.1853 - accuracy: 0.9514\n",
      "Epoch 412/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1858 - accuracy: 0.9492\n",
      "Epoch 413/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1842 - accuracy: 0.9492: 0s - loss: 0.1835 - accuracy: 0.94\n",
      "Epoch 414/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1833 - accuracy: 0.9514\n",
      "Epoch 415/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.1834 - accuracy: 0.9536\n",
      "Epoch 416/500\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.1831 - accuracy: 0.9470\n",
      "Epoch 417/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1806 - accuracy: 0.9492\n",
      "Epoch 418/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1800 - accuracy: 0.9536\n",
      "Epoch 419/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1786 - accuracy: 0.9536\n",
      "Epoch 420/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1779 - accuracy: 0.9536\n",
      "Epoch 421/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1773 - accuracy: 0.9492\n",
      "Epoch 422/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1775 - accuracy: 0.9514\n",
      "Epoch 423/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1750 - accuracy: 0.9492\n",
      "Epoch 424/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1755 - accuracy: 0.9492\n",
      "Epoch 425/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1735 - accuracy: 0.9470\n",
      "Epoch 426/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1731 - accuracy: 0.9514\n",
      "Epoch 427/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.1730 - accuracy: 0.9426\n",
      "Epoch 428/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.1717 - accuracy: 0.9514\n",
      "Epoch 429/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1716 - accuracy: 0.9470\n",
      "Epoch 430/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1707 - accuracy: 0.9470\n",
      "Epoch 431/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1696 - accuracy: 0.9514\n",
      "Epoch 432/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1703 - accuracy: 0.9492\n",
      "Epoch 433/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1686 - accuracy: 0.9536\n",
      "Epoch 434/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1675 - accuracy: 0.9514\n",
      "Epoch 435/500\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.1676 - accuracy: 0.9492 0s - loss: 0.1711 - accuracy: 0.94\n",
      "Epoch 436/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.1662 - accuracy: 0.9492\n",
      "Epoch 437/500\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.1657 - accuracy: 0.9492\n",
      "Epoch 438/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1650 - accuracy: 0.9448\n",
      "Epoch 439/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1635 - accuracy: 0.9492\n",
      "Epoch 440/500\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.1626 - accuracy: 0.9514\n",
      "Epoch 441/500\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.1619 - accuracy: 0.9470\n",
      "Epoch 442/500\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.1616 - accuracy: 0.9448\n",
      "Epoch 443/500\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.1617 - accuracy: 0.9470\n",
      "Epoch 444/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1718 - accuracy: 0.9470\n",
      "Epoch 445/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1636 - accuracy: 0.9492\n",
      "Epoch 446/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1688 - accuracy: 0.9470\n",
      "Epoch 447/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.1645 - accuracy: 0.9470\n",
      "Epoch 448/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1622 - accuracy: 0.9470\n",
      "Epoch 449/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1667 - accuracy: 0.9492\n",
      "Epoch 450/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1700 - accuracy: 0.9536\n",
      "Epoch 451/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1712 - accuracy: 0.9404\n",
      "Epoch 452/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.1737 - accuracy: 0.9470\n",
      "Epoch 453/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.1667 - accuracy: 0.9426\n",
      "Epoch 454/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1613 - accuracy: 0.9404\n",
      "Epoch 455/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.1570 - accuracy: 0.9448\n",
      "Epoch 456/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.1551 - accuracy: 0.9470\n",
      "Epoch 457/500\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.1456 - accuracy: 0.95 - 0s 7ms/step - loss: 0.1537 - accuracy: 0.9470\n",
      "Epoch 458/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1541 - accuracy: 0.9426\n",
      "Epoch 459/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1549 - accuracy: 0.9470\n",
      "Epoch 460/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1550 - accuracy: 0.9514\n",
      "Epoch 461/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1559 - accuracy: 0.9514\n",
      "Epoch 462/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.1519 - accuracy: 0.9492\n",
      "Epoch 463/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1498 - accuracy: 0.9492\n",
      "Epoch 464/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.1496 - accuracy: 0.9492\n",
      "Epoch 465/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1482 - accuracy: 0.9492\n",
      "Epoch 466/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1480 - accuracy: 0.9492\n",
      "Epoch 467/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1476 - accuracy: 0.9492\n",
      "Epoch 468/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1469 - accuracy: 0.9426\n",
      "Epoch 469/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1470 - accuracy: 0.9448\n",
      "Epoch 470/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1463 - accuracy: 0.9448\n",
      "Epoch 471/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.1454 - accuracy: 0.9492\n",
      "Epoch 472/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1451 - accuracy: 0.9492: 0s - loss: 0.1458 - accuracy: 0.94\n",
      "Epoch 473/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.1448 - accuracy: 0.9492\n",
      "Epoch 474/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1452 - accuracy: 0.9492\n",
      "Epoch 475/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1473 - accuracy: 0.9514\n",
      "Epoch 476/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1518 - accuracy: 0.9470\n",
      "Epoch 477/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1498 - accuracy: 0.9470\n",
      "Epoch 478/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.1453 - accuracy: 0.9470\n",
      "Epoch 479/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1448 - accuracy: 0.9470\n",
      "Epoch 480/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1437 - accuracy: 0.9448\n",
      "Epoch 481/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.1434 - accuracy: 0.9514\n",
      "Epoch 482/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.1433 - accuracy: 0.9426\n",
      "Epoch 483/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1426 - accuracy: 0.9492\n",
      "Epoch 484/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1423 - accuracy: 0.9514\n",
      "Epoch 485/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1421 - accuracy: 0.9448\n",
      "Epoch 486/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1407 - accuracy: 0.9448\n",
      "Epoch 487/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1400 - accuracy: 0.9470\n",
      "Epoch 488/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.1404 - accuracy: 0.9470\n",
      "Epoch 489/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1404 - accuracy: 0.9470\n",
      "Epoch 490/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.1393 - accuracy: 0.9492\n",
      "Epoch 491/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1386 - accuracy: 0.9492\n",
      "Epoch 492/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.1384 - accuracy: 0.9426\n",
      "Epoch 493/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1369 - accuracy: 0.9514\n",
      "Epoch 494/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1383 - accuracy: 0.9514\n",
      "Epoch 495/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1368 - accuracy: 0.9448\n",
      "Epoch 496/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.1355 - accuracy: 0.9514\n",
      "Epoch 497/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1358 - accuracy: 0.9470\n",
      "Epoch 498/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1356 - accuracy: 0.9514\n",
      "Epoch 499/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1351 - accuracy: 0.9492\n",
      "Epoch 500/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1351 - accuracy: 0.9492\n"
     ]
    }
   ],
   "source": [
    "  model = Sequential()\n",
    "  model.add(Embedding(total_words, 64, input_length=max_sequence_len-1))\n",
    "  model.add(Bidirectional(LSTM(20)))\n",
    "  model.add(Dense(total_words, activation='softmax'))\n",
    "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "  history = model.fit(xs, ys, epochs=500, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_graphs(history, string):\n",
    "  plt.plot(history.history[string])\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(string)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_graphs(history, 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Yash\\AppData\\Local\\Temp/ipykernel_7996/3548191588.py:7: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Yash\\AppData\\Local\\Temp/ipykernel_7996/3548191588.py:7: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Laurence went to dublin til leg through lanigan hoops hoops rose had for new for stepped and ball all think ball ball all groups couples the rose ladies ladies runctions cried meelia murther mccarthy murther murther right glisten glisten glisten glisten right hoops rose rose runctions round rose rose a rose rose glisten hall had a rose glisten glisten glisten boys for for out and all relations gathered all nelly peggy make your eyes glisten hall glisten glisten glisten boys didnt youd a glisten hall glisten rose cried meelia murther glisten glisten boys relations didnt replied to call me a party for her youd\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"Laurence went to dublin\"\n",
    "next_words = 100\n",
    "  \n",
    "for _ in range(next_words):\n",
    "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "\tpredicted = model.predict_classes(token_list, verbose=0)\n",
    "\toutput_word = \"\"\n",
    "\tfor word, index in tokenizer.word_index.items():\n",
    "\t\tif index == predicted:\n",
    "\t\t\toutput_word = word\n",
    "\t\t\tbreak\n",
    "\tseed_text += \" \" + output_word\n",
    "print(seed_text)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8a460da068ad21e825cd853dee63733b8b91400b72d458b93ad7c646498b211f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
