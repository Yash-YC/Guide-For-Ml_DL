{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "from sklearn.datasets import fetch_california_housing \r\n",
    "from sklearn.model_selection import train_test_split \r\n",
    "from sklearn.preprocessing import StandardScaler \r\n",
    "from tensorflow import keras \r\n",
    "housing = fetch_california_housing() \r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split( housing.data, housing.target) \r\n",
    "X_train, X_valid, y_train, y_valid = train_test_split( X_train_full, y_train_full) \r\n",
    "scaler = StandardScaler() \r\n",
    "X_train_scaled = scaler.fit_transform(X_train) \r\n",
    "X_valid_scaled = scaler.transform(X_valid) \r\n",
    "X_test_scaled = scaler.transform(X_test)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "model = keras.models.Sequential([ keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]), keras.layers.Dense(1) ])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 4s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "mse_test = model.evaluate(X_test, y_test) \r\n",
    "X_new = X_test[:3] # pretend these are new instances \r\n",
    "y_pred = model.predict(X_new)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "162/162 [==============================] - 0s 2ms/step - loss: nan\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "input = keras.layers.Input(shape=X_train.shape[1:]) \r\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input) \r\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1) \r\n",
    "concat = keras.layers.Concatenate()([input, hidden2])\r\n",
    "output = keras.layers.Dense(1)(concat) \r\n",
    "model = keras.models.Model(inputs=[input], outputs=[output])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "input_A = keras.layers.Input(shape=[5]) \r\n",
    "input_B = keras.layers.Input(shape=[6]) \r\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B) \r\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1) \r\n",
    "concat = keras.layers.concatenate([input_A, hidden2]) \r\n",
    "output = keras.layers.Dense(1)(concat) \r\n",
    "model = keras.models.Model(inputs=[input_A, input_B], outputs=[output])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"sgd\") \r\n",
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:] \r\n",
    "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:] \r\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:] \r\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3] \r\n",
    "history = model.fit((X_train_A, X_train_B), y_train, epochs=20, validation_data=((X_valid_A, X_valid_B), y_valid))\r\n",
    "mse_test = model.evaluate((X_test_A, X_test_B), y_test) \r\n",
    "y_pred = model.predict((X_new_A, X_new_B))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 2s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "162/162 [==============================] - 0s 2ms/step - loss: nan\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "y_pred"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[nan],\n",
       "       [nan],\n",
       "       [nan]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "class WideAndDeepModel(keras.models.Model): \r\n",
    "    def __init__(self, units=30, activation=\"relu\", **kwargs): \r\n",
    "        super().__init__(**kwargs) # handles standard args (e.g., name) \r\n",
    "        self.hidden1 = keras.layers.Dense(units, activation=activation) \r\n",
    "        self.hidden2 = keras.layers.Dense(units, activation=activation) \r\n",
    "        self.main_output = keras.layers.Dense(1) \r\n",
    "        self.aux_output = keras.layers.Dense(1) \r\n",
    "    def call(self, inputs): \r\n",
    "        input_A, input_B = inputs \r\n",
    "        hidden1 = self.hidden1(input_B) \r\n",
    "        hidden2 = self.hidden2(hidden1) \r\n",
    "        concat = keras.layers.concatenate([input_A, hidden2]) \r\n",
    "        main_output = self.main_output(concat) \r\n",
    "        aux_output = self.aux_output(hidden2) \r\n",
    "        return main_output, aux_output \r\n",
    "\r\n",
    "model = WideAndDeepModel()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.save(\"my_keras_model.h5\")## saving model\r\n",
    "model = keras.models.load_model(\"my_keras_model.h5\") \r\n",
    "\r\n",
    "# This will work when using the Sequential API or the Functional API, but unfortunately not when using Model subclassing. \r\n",
    "# How‚Äê ever, you can use save_weights() and load_weights() to at least save and restore the model parameters \r\n",
    "#(but you will need to save and restore everything else yourself).\r\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('ML_algo': conda)"
  },
  "interpreter": {
   "hash": "3a32990f6da0d7abf7182fdf4d416d4dc1a912d9d1503f9139207ed8cae052ef"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}